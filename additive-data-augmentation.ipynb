{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# find all sameas links from english to de, fr, es and create three dicts\n",
    "# for each item in language specific dict\n",
    "    # find all the triples for language specific subject and uri obj\n",
    "    # create triple arrays with en subj and replaced obj\n",
    "    # find all the triples for language specific subject and non uri obj\n",
    "    # create triple arrays with en subj\n",
    "    # write triples to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time, os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# languages array\n",
    "lang_arr = ['en','de','es','fr']\n",
    "# non-english lang array\n",
    "ne_lang_arr = ['de','es','fr']\n",
    "# output dir\n",
    "out_dir = './ada_files/'\n",
    "# init sparql\n",
    "sparql = SPARQLWrapper(\"http://porque.cs.upb.de:3030/dbp-all-2016-10/sparql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsolete\n",
    "# create query template\n",
    "# sameas_qry_tmplt = '''\n",
    "# PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "# SELECT \n",
    "# ?s1 ?s2 \n",
    "# WHERE {\n",
    "# ?s1 owl:sameAs ?s2 . \n",
    "# FILTER(STRSTARTS(str(?s1 ), \"http://dbpedia.org/resource/\" ) &&\n",
    "#  STRSTARTS(str(?s2 ), \"http://%s.dbpedia.org/resource/\" ))\n",
    "# } LIMIT %s\n",
    "# OFFSET %s\n",
    "# '''\n",
    "\n",
    "# uri_trpl_qry = '''\n",
    "# SELECT \n",
    "# ?p ?o\n",
    "# WHERE { \n",
    "# <%s> ?p1 ?o1 .\n",
    "# FILTER(isURI(?o1))\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# othr_trpl_qry = '''\n",
    "# SELECT \n",
    "# ?p ?o\n",
    "# WHERE { \n",
    "# <%s> ?p1 ?o1 .\n",
    "# FILTER(!isURI(?o1))\n",
    "# }\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file_tmplt = out_dir + \"extracted_mappings/extracted_en-%s_links.ttl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sameas_dict = dict()\n",
    "for lang in ne_lang_arr:\n",
    "    cur_map = dict()\n",
    "    #fetch sameas links\n",
    "    with open(mapping_file_tmplt%(lang),'r') as mapping_file:\n",
    "        # read line by line\n",
    "        while (line_items := mapping_file.readline().rstrip().split()):\n",
    "            s1 = line_items[0]\n",
    "            s2 = line_items[2]\n",
    "            # read results and load mappings to cur_map\n",
    "            cur_map[s1] = s2\n",
    "    # load cur_map to sameas_dictraphdb is good. And someone could try out ox\n",
    "    sameas_dict[lang] = cur_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139521\n",
      "1005148\n",
      "1359645\n"
     ]
    }
   ],
   "source": [
    "print(len(sameas_dict['de']))\n",
    "print(len(sameas_dict['es']))\n",
    "print(len(sameas_dict['fr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "LITERAL_TYPE = 'L'\n",
    "URI_TYPE = 'U'\n",
    "OTHER_TYPE = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_and_write(s, p, o, link_map, file_arr):\n",
    "    out_file = None\n",
    "    out_line = None\n",
    "    # find if subj linked\n",
    "    subj_lnkd = s in link_map\n",
    "    # type of obj is other\n",
    "    o_type = OTHER_TYPE\n",
    "    o_lnkd = False\n",
    "    \n",
    "    if re.match('^<.+>$', o):\n",
    "        o_type = URI_TYPE\n",
    "        # find if obj linked\n",
    "        o_lnkd = o in link_map\n",
    "    elif re.match('^\".+\".*', o):\n",
    "        o_type = LITERAL_TYPE\n",
    "    #print('Object:', o, '\\tObj Type', o_type, '\\tObj linked', o_lnkd)\n",
    "    # if both linked, write to 0\n",
    "    if(subj_lnkd and o_lnkd):\n",
    "        out_file = file_arr[0]\n",
    "        out_line = link_map[s] + ' ' + p + ' ' + link_map[o] + ' .\\n'\n",
    "    elif((not subj_lnkd) and o_lnkd):\n",
    "        out_file = file_arr[2]\n",
    "        out_line = s + ' ' + p + ' ' + link_map[o] + ' .\\n'\n",
    "    # if subj linked\n",
    "    elif(subj_lnkd and (not o_lnkd)):\n",
    "        # if obj is literal write to 1\n",
    "        if(o_type == LITERAL_TYPE):\n",
    "            out_file = file_arr[1]\n",
    "        # rest, write to 2\n",
    "        else:\n",
    "            out_file = file_arr[2]\n",
    "        out_line = link_map[s] + ' ' + p + ' ' + o + ' .\\n'\n",
    "    # if subj and obj both not linked\n",
    "    else:\n",
    "        # if obj is literal, write to 4\n",
    "        if(o_type == LITERAL_TYPE):\n",
    "            out_file = file_arr[4]\n",
    "        # is obj is not literal, write to 3\n",
    "        else:\n",
    "            out_file = file_arr[3]\n",
    "            #print('This object should not be literal:', o, ' type:', o_type)\n",
    "            \n",
    "        out_line = s + ' ' + p + ' ' + o + ' .\\n'\n",
    "    out_file.write(out_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mappingbased_literals_de.ttl\n",
      "Processing commons_page_links_de.ttl\n",
      "Processing category_labels_de.ttl\n",
      "Processing instance_types_de.ttl\n",
      "Processing skos_categories_de.ttl\n",
      "Processing persondata_de.ttl\n",
      "Processing interlanguage_links_de.ttl\n",
      "Processing long_abstracts_de.ttl\n",
      "Processing labels_de.ttl\n",
      "Processing article_categories_de.ttl\n",
      "Processing short_abstracts_de.ttl\n",
      "Processing mappingbased_objects_de.ttl\n",
      "Processing disambiguations_de.ttl\n",
      "Processing short_abstracts_es.ttl\n",
      "Processing instance_types_es.ttl\n",
      "Processing commons_page_links_es.ttl\n",
      "Processing interlanguage_links_es.ttl\n",
      "Processing persondata_es.ttl\n",
      "Processing skos_categories_es.ttl\n",
      "Processing mappingbased_objects_es.ttl\n",
      "Processing long_abstracts_es.ttl\n",
      "Processing mappingbased_literals_es.ttl\n",
      "Processing category_labels_es.ttl\n",
      "Processing article_categories_es.ttl\n",
      "Processing disambiguations_es.ttl\n",
      "Processing labels_es.ttl\n",
      "Processing instance_types_fr.ttl\n",
      "Processing article_categories_fr.ttl\n",
      "Processing french_population_fr.ttl\n",
      "Processing disambiguations_fr.ttl\n",
      "Processing long_abstracts_fr.ttl\n",
      "Processing category_labels_fr.ttl\n",
      "Processing skos_categories_fr.ttl\n",
      "Processing mappingbased_literals_fr.ttl\n",
      "Processing mappingbased_objects_fr.ttl\n",
      "Processing commons_page_links_fr.ttl\n",
      "Processing labels_fr.ttl\n",
      "Processing short_abstracts_fr.ttl\n",
      "Processing interlanguage_links_fr.ttl\n",
      "Processing persondata_fr.ttl\n"
     ]
    }
   ],
   "source": [
    "enrich_dir ='/data-disk/kg-fusion/enrichment-files/'\n",
    "triples_dir = \"/data-disk/kg-fusion/\"\n",
    "# For each language\n",
    "for lang in ne_lang_arr:\n",
    "    link_map = sameas_dict[lang]\n",
    "    directory = os.fsencode(triples_dir + lang + '/')\n",
    "    out_dir = enrich_dir + lang + '/'\n",
    "    fully_lnkd_fp = out_dir + 'fully_lnkd.nt'\n",
    "    lnkd_ltrls_fp = out_dir + 'lnkd_ltrls.nt'\n",
    "    part_lnkd_fp = out_dir + 'part_lnkd.nt'\n",
    "    non_lnkd_fp = out_dir + 'non_lnkd.nt'\n",
    "    nl_ltrls_fp = out_dir + 'nl_ltrls.nt'\n",
    "    \n",
    "    # create directories if not exists\n",
    "    os.makedirs(os.path.dirname(fully_lnkd_fp), exist_ok=True)\n",
    "    \n",
    "    with open(fully_lnkd_fp,'w') as fully_lnkd, \\\n",
    "        open(lnkd_ltrls_fp,'w') as lnkd_ltrls, \\\n",
    "        open(part_lnkd_fp,'w') as part_lnkd, \\\n",
    "        open(non_lnkd_fp,'w') as non_lnkd, \\\n",
    "        open(nl_ltrls_fp,'w') as nl_ltrls:\n",
    "        file_arr = [fully_lnkd, lnkd_ltrls, part_lnkd, non_lnkd, nl_ltrls]\n",
    "        # For each file\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith(\".ttl\"):\n",
    "                print('Processing',filename)\n",
    "                with open(directory+file,'r') as cur_file:\n",
    "                    # For each line\n",
    "                    while (line := cur_file.readline().rstrip()):\n",
    "                        if(re.match('^#.*',line[0])):\n",
    "                            continue\n",
    "                        # extract items\n",
    "                        line_items = re.match('(<.+?>)\\s(<.+?>)\\s(.+)\\s\\\\.', line).groups()\n",
    "                        # Find mappings\n",
    "                        s = line_items[0]\n",
    "                        p = line_items[1]\n",
    "                        o = line_items[2]\n",
    "                        #print(s,p,o)\n",
    "                        identify_and_write(s, p, o, link_map, file_arr)\n",
    "                            \n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files parting completed.\n"
     ]
    }
   ],
   "source": [
    "print('Files parting completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
